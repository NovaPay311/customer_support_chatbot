# --- Chatbot Configuration ---

# The API key for the LLM provider (e.g., OpenAI, Azure OpenAI, etc.)
# This is mandatory for the RAG chain to function.
OPENAI_API_KEY="YOUR_LLM_API_KEY_HERE"

# API Keys for Multi-LLM Support
# Uncomment and provide keys for the models you want to use.
# GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
# ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY"

# The base URL for the OpenAI-compatible API. 
# Use the default if you are using OpenAI. Change this if you are using a self-hosted or other provider.
OPENAI_API_BASE="https://api.openai.com/v1"

# The name of the LLM model to use for generating answers.
# Recommended: gpt-4.1-mini, gemini-2.5-flash, or a similar fast model.
# The code will automatically select the correct API based on the model name and available API key.
LLM_MODEL_NAME="gpt-4.1-mini"

# The name of the embedding model.
# Recommended: text-embedding-ada-002 or a similar fast model.
EMBEDDING_MODEL_NAME="text-embedding-ada-002"

# --- Vector Database Configuration (For Production/Scalability) ---

# Set the VECDB_TYPE to 'CHROMA' for local quick start, or 'PINECONE'/'WEAVIATE' for production.
# VECDB_TYPE="CHROMA"
# VECDB_TYPE="PINECONE"
# VECDB_TYPE="WEAVIATE"

# --- ChromaDB (Local/Quick Start) ---
# CHROMA_PERSIST_DIRECTORY="./chroma_db"

# --- Pinecone Configuration ---
# PINECONE_API_KEY="YOUR_PINECONE_API_KEY"
# PINECONE_ENVIRONMENT="YOUR_PINECONE_ENVIRONMENT"
# PINECONE_INDEX_NAME="novapay-index"

# --- Weaviate Configuration ---
# WEAVIATE_URL="YOUR_WEAVIATE_URL"
# WEAVIATE_API_KEY="YOUR_WEAVIATE_API_KEY"
# WEAVIATE_INDEX_NAME="NovaPayKB"

# --- Conversational Memory (For Scalable Context) ---

# For production, we would use an external store like Redis.
# MEMORY_TYPE="REDIS"
# REDIS_URL="redis://localhost:6379"

# --- API Configuration ---

# The port on which the Flask API will run
FLASK_PORT=5000

# The secret key for Flask sessions (optional, but good practice)
# FLASK_SECRET_KEY="A_VERY_SECRET_KEY"
